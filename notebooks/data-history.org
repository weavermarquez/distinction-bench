#+title: Data History
#+description: An overview of significant findings across different versions of the benchmark

* V0: Single Notebook Version

The task:
- Evaluate 8 Regular Parens forms e.g. ((())())
- N=500
- claude-opus-4-5, no reasoning.
- gemini-3-pro-preview, no reasoning.
#+begin_example
=== Target Count Distribution ===
  0:  1
  1: РќѕРќѕРќѕ 12
  2: РќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕ 43
  3: РќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕ 99
  4: РќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕ 141
  5: РќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕ 118
  6: РќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕРќѕ 64
  7: РќѕРќѕРќѕРќѕРќѕ 20
  8:  2

=== Random Baselines ===
  Per-item:       50.0% (coin flip)
  All-correct:    0.39% (8 coin flips)
  Count-match:    20.0% (P(random guess correct) = ╬Б P(k)┬▓)
  Count MAE:      1.54 (mean absolute error, guess ~ P(k))

=== Average Steps per Difficulty ===
  1. easy     : ~3.3 steps
  2. medium   : ~8.6 steps
  3. hard     : ~12.7 steps
  4. lunatic  : ~14.7 steps
  5. extra    : ~18.1 steps
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
=== Results by Model ===
claude-opus-4-5-20251101 (n=500):
  Per-item:      62.8%
  All-correct:   4.0% (20/500)
  Count match:   14.6%
  Count MAE:     1.83
gemini-3-pro-preview (n=500):
  Per-item:      71.1%
  All-correct:   16.6% (83/500)
  Count match:   32.4%
  Count MAE:     1.15

=== Accuracy by Difficulty ===
claude-opus-4-5-20251101:
  1. easy       76.4% per-item   14.0% all-correct  (n=100)
  2. medium     65.1% per-item    1.0% all-correct  (n=100)
  3. hard       54.0% per-item    2.0% all-correct  (n=100)
  4. lunatic    58.5% per-item    2.0% all-correct  (n=100)
  5. extra      60.0% per-item    1.0% all-correct  (n=100)
gemini-3-pro-preview:
  1. easy       91.1% per-item   56.0% all-correct  (n=100)
  2. medium     79.6% per-item   18.0% all-correct  (n=100)
  3. hard       55.4% per-item    0.0% all-correct  (n=100)
  4. lunatic    64.0% per-item    7.0% all-correct  (n=100)
  5. extra      65.5% per-item    2.0% all-correct  (n=100)

=== Accuracy by Target ===
claude-opus-4-5-20251101:
  marked      : 57.4% (1199/2089)
  unmarked    : 68.7% (1313/1911)
gemini-3-pro-preview:
  marked      : 70.8% (1479/2089)
  unmarked    : 71.5% (1366/1911)
#+end_example

* v1: Reprodicible version built on inspect-ai
- mixed brackets: balanced / jumbled
  - balanced: (РїЕсђѕсђЅсђѕРїЕсђїсђЇРїфсђЅсђѕсђЅРїфРїЕсђѕРїЕсђїсђЇРїфРїЕРїфРїЕсђїсђЇРїфсђЅРїфРїЕРїф)(РїЕсђѕсђЅРїф)
  - mismatched:сђј(сђі(сђЅРЪЕсђјсђјсђЇсђЈ]РЪе}[РЪе{сђј]сђЈсђі]сђјРїф>РїЕсђїсђі>]сђіРЪЕРЪЕсђЅсђЈ(<][РЪЕсђЅ
- parens only: ((((()))()()))(())

64k thinking on 2 epochs of 1000 samples. Spent way too much money ­Ъў▒
#+begin_example
=== composite_lof_task ===
Model: anthropic/claude-opus-4-5-20251101
Groups: 2055
Date: 2025-12-16T01:43:50+00:00

Metrics:
  Per-item accuracy: 94.4%
  All-correct:       85.5% (1756/2055)
#+end_example

The same 5x3 sample/epochs. GPT-5.2 on reasoning-level=high. Balanced noisy parens.
#+begin_example
=== composite_lof_task ===
Model: openai/gpt-5.2
Groups: 30
Date: 2025-12-16T00:36:57+00:00

Metrics:
  Per-item accuracy:    94.2%
  All-correct:          76.7% (23/30)
  Structure accuracy:   75.0%
#+end_example

Gemini 3 Pro, reasoning-level=high. 30x3 sample / epochs. Balanced noisy parens. IDK if it's just the way I any reasoning-effort=high request is, but this took 30 freaking minutes. I have noticed that most reasoning_effort=high tests I ran on gemini AI studio took about 3 minutes for most tasks. IDK if that's just baked in.
#+begin_example
=== composite_lof_task ===
Model: google/gemini-3-pro-preview
Groups: 90
Date: 2025-12-16T04:02:04+00:00

Metrics:
  Per-item accuracy:    88.3%
  All-correct:          66.7% (60/90)
  Structure accuracy:   20.6%
#+end_example



One interesting experiment that I did manage to get out of this was running the same data set on the same model: Opus, on three different representations of the same forms.

A) 10k thinking on 5 samples, 3 epochs each. mismatched noisy parens.
#+begin_example
=== composite_lof_task ===
Model: anthropic/claude-opus-4-5-20251101
Groups: 15
Date: 2025-12-15T23:19:22+00:00

Metrics:
  Per-item accuracy: 71.7%
  All-correct:       40.0% (6/15)
#+end_example


B) 10k thinking on the same 5 samples, 3 epochs each. Balanced noisy parens.
#+begin_example
=== composite_lof_task ===
Model: anthropic/claude-opus-4-5-20251101
Groups: 15
Date: 2025-12-15T23:10:31+00:00

Metrics:
  Per-item accuracy: 96.7%
  All-correct:       86.7% (13/15)
#+end_example

C) Opus 4.5, 10k thinking on the same 5 samples, 3 epochs each. Regular parens (())
#+begin_example
#+RESULTS:
=== composite_lof_task ===
Model: anthropic/claude-opus-4-5-20251101
Groups: 15
Date: 2025-12-15T22:40:38+00:00

Metrics:
  Per-item accuracy: 86.7%
  All-correct:       53.3% (8/15)
#+end_example
   
And lastly, Sonnet 4.5.
D) Claude Sonnet 4.5, 10k reasoning tokens. 10x3 samples. Parens notation (same as the one above)
#+begin_example
=== composite_lof_task ===
Model: anthropic/claude-sonnet-4-5-20250929
Groups: 30
Date: 2025-12-16T00:26:03+00:00

Metrics:
  Per-item accuracy:    55.8%
  All-correct:          10.0% (3/30)
  Structure accuracy:   22.5%
#+end_example
